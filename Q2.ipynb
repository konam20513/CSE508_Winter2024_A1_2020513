{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"preprocessed_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy English language model for NLP tasks\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def pre_query(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [tok.text for tok in doc if not tok.is_stop and not tok.is_punct and not tok.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating inverted index\n",
    "def inv_index(folder):\n",
    "    \n",
    "    # initializing empty dictionary\n",
    "    inv = {}  \n",
    "    \n",
    "    # iterating over each file in folder\n",
    "    for filename in os.listdir(folder):  \n",
    "        \n",
    "        # reading each one\n",
    "        with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file: \n",
    "            \n",
    "            # storing set of unique words from text file \n",
    "            words = set(file.read().split())  \n",
    "            \n",
    "            for word in words:\n",
    "                \n",
    "                # updating each word with filename\n",
    "                inv.setdefault(word, set()).add(filename)  \n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving inverted index as pickle file\n",
    "def save(inverted_index, file_name):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(inverted_index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, operations, inverted_index):\n",
    "    # splitting the query\n",
    "    terms = query.split()\n",
    "\n",
    "    # preprocess the first term \n",
    "    pre_first_term = pre_query(terms[0])\n",
    "    \n",
    "    # initializing result set\n",
    "    res = set()\n",
    "    for term in pre_first_term:\n",
    "        res = res.union(inverted_index.get(term, set()))\n",
    "\n",
    "    # iterate over the operations and the remaining terms\n",
    "    for i, op in enumerate(operations):\n",
    "        if i + 1 < len(terms):\n",
    "            preprocessed_term = pre_query(terms[i + 1])\n",
    "            next_set = set()\n",
    "            for term in preprocessed_term:\n",
    "                next_set = next_set.union(inverted_index.get(term, set()))\n",
    "\n",
    "            if op == 'AND':\n",
    "                res = res.intersection(next_set)\n",
    "            elif op == 'OR':\n",
    "                res = res.union(next_set)\n",
    "            elif op == 'AND NOT':\n",
    "                res = res.difference(next_set)\n",
    "            elif op == 'OR NOT':\n",
    "                all_docs = set.union(*[set(v) for v in inverted_index.values()])\n",
    "                res = res.union(all_docs.difference(next_set))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name to save file\n",
    "index_file = \"inverted_index.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and saving inv index\n",
    "inverted_index = inv_index(folder)\n",
    "save(inverted_index, index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading saved inverted index using pickle\n",
    "def load_inverted_index(file_name):\n",
    "    with open(file_name, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# loading inv index\n",
    "loaded_index = load_inverted_index(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: car OR bag AND NOT canister\n",
      "Number of documents retrieved for query 1: 31\n",
      "Names of the documents retrieved for query 1: file863.txt, file363.txt, file174.txt, file930.txt, file746.txt, file981.txt, file699.txt, file956.txt, file892.txt, file118.txt, file686.txt, file698.txt, file73.txt, file860.txt, file797.txt, file864.txt, file264.txt, file780.txt, file886.txt, file166.txt, file466.txt, file313.txt, file459.txt, file942.txt, file404.txt, file665.txt, file682.txt, file542.txt, file573.txt, file3.txt, file738.txt\n"
     ]
    }
   ],
   "source": [
    "# processing unser queries user queries\n",
    "n = int(input(\"Enter number of queries: \"))  \n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    query = input(f\"Enter query {i+1}: \")\n",
    "    operations = input(\"Enter operations separated by comma: \").split(\", \")\n",
    "    \n",
    "    pre_q= pre_query(query)\n",
    "    \n",
    "    result = process_query(query, operations, loaded_index)\n",
    "    \n",
    "    formatted_query = pre_q[0] if pre_q else \"\"\n",
    "    for op, term in zip(operations, pre_q[1:]):\n",
    "        formatted_query += f\" {op.upper()} {term}\"\n",
    "\n",
    "    print(f\"Query {i+1}: {formatted_query}\")\n",
    "    print(f\"Number of documents retrieved for query {i+1}: {len(result)}\")\n",
    "    print(f\"Names of the documents retrieved for query {i+1}: {', '.join(result)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
